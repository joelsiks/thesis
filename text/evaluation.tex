
When evaluating memory allocators, two primary metrics stand out: performance and memory usage, specifically fragmentation. Performance entails measuring the duration it takes to perform certain operations, while fragmentation assesses how efficiently the allocator utilizes the available memory. These metrics directly address the challenges of optimizing memory allocation for ZGC.

\subsection{Evaluation Delimitations}

Due to time constraints, the allocator designed in this work will not be integrated into ZGC. While integrating into ZGC would offer a natural environment for testing and evaluating the allocator, this limitation impacts how definitive the evaluation results are.

The optimized version of the allocator is specifically tailored for ZGC, restricting the patterns of allocations and frees that can be used. This makes it challenging to find overlapping areas for a fair comparison between different versions of the allocator and to identify suitable patterns within the constraints of allocation and heap size imposed by the optimized version and ZGC. Even when applying the same pattern of allocations and frees, the heaps of the different versions will be filled differently and at different rates due to varying block header sizes, leading to different memory usage. For instance, when the general version's heap is full, the optimized version may still have available memory. Additionally, the optimized version lacks immediate coalescing, further complicating when to perform explicit coalescing to ensure the same allocation requests can be fulfilled across all versions.

Due to these challenges, the evaluation is limited to cases that can be fairly compared and reasoned about. While this method is not exhaustive, which is a common issue in allocator evaluations, it provides a basis for assessing the relative performance of the allocator versions.

\subsection{Allocator Configurations}

The three different versions of the TLSF allocator developed in this work that will be evaluated and compared in this section are: the reference TLSF implementation, the general version, and the optimized version for ZGC. 

\newpage

The general and optimized versions are described by their configuration variables from the base implementation, as shown in Table~\ref{table:configuration-variables}.

\begin{table}[H]
    \centering
    \begin{tabular}{lp{2cm}p{6.9cm}}
    \textbf{{Configuration Variable}} & \textbf{{General}} & \textbf{{Optimized}} \\ \hline
    First-Level Index         & 32       & 14     \\ \hline
    Second-Level Index        & 32       & 4      \\ \hline
    Minimum Block Size        & 32       & 16     \\ \hline
    Block Header Size         & 32       & 0      \\ \hline
    Use Second Levels         & True     & False  \\ \hline
    Use Deferred Coalescing   & False    & True
    \end{tabular}
    \caption{Configuration variables for the general and optimized versions of the allocator.}
    \label{table:configuration-variables}
\end{table}

\subsection{Measuring Performance}

To fairly compare the versions of the allocators when doing benchmarks that call \texttt{free()}, immediate coalescing will be disabled for the reference and general versions by not attempting to implicitly coalesce blocks in a call to \texttt{free()}. This is because the optimized version does not support immediate coalescing and only implements explicit coalescing, which is intentionally slower due to the fact it should be used only as a last resort. Disabling immediate coalescing is also reasonable from the perspective that it is likely not desirable as often in Z, making the test more adapted to the intended use case of the optimized version.

Performance will be measured by looking at three different benchmarks: single allocation, single free, and patterns that combine both allocation and free requests.

Three scenarios for single allocation are considered, all focusing on a fixed size of 64 bytes. Only allocating a single size comes from TLSF's constraint on the maximum number of instructions required for block allocation. Consequently, assessing multiple sizes becomes redundant as allocation performance primarily depends on the availability of suitable blocks within the free-lists. The first two cases that are considered are when there is a block in the heap that perfectly aligns with the allocation size and when there is only one block that is larger than the allocation size. The latter case requires, in addition to doing the same operations as in the first case, searching the bitmap for a larger block and splitting it. This case is also used as the worst-case test by M. Masmano et al.~\cite{TLSF} for the evaluation of the original TLSF design. The third case will be performing the first case and also initializing the returned memory by filling it with zeros. This is to see how initializing the memory affects performance, as this is done after allocating memory in ZGC. Measuring these three cases will provide insight into both normal and worst-case allocation performance.

Measuring single-frees is more straightforward to reason about than allocation when immediate coalescing is disabled. Calling \texttt{free()} with coalescing disabled can only be performed in a single way, by inserting the free block into the appropriate free-list. The test that will be performed will allocate 64 bytes and then call free on the returned address immediately after. Time will be measured right before and after the call to \texttt{free()}.

In a more comprehensive performance test, a pattern of both allocation and free requests will be applied. Due to the limitations mentioned in the previous section, patterns that adhere to the requirements of the optimized version are used. Patterns will be recorded from the GNU utilities  \texttt{cat}, \texttt{grep}, \texttt{ls}, \texttt{nano}, \texttt{sed} and \texttt{wc}, which are then applied to the different versions of the allocator to compare performance. The reason this is done instead of just using the allocators in the programs is to highlight only the performance of allocating and freeing. Using the allocators in the programs would spend significantly more time doing program logic instead of using the allocator, making it more difficult to see the performance impact of changing the allocator.

All benchmarks will be measured using wall clock time to see their execution time and repeated 100,000 times to collect a mean result. Benchmarks are repeated to remove any jitter and noise from the results so that stable results are reported.

\subsubsection{Programs to Record Patterns From}

Table~\ref{table:pattern-programs} shows the specific commands and versions of the programs used to record patterns. All programs except \texttt{ls} have performed their respective actions on the same file called \texttt{pi.txt}, which contains the first 10000 decimals of pi, line-broken every 100:th decimal to create 100 lines of 100 decimals. The \texttt{ls} command has been run inside a directory containing only the file \texttt{pi.txt}. The \texttt{nano} command opens \texttt{pi.txt} and exits immediately.

\begin{table}[H]
\centering
\begin{tabular}{llp{10.4cm}}
\textbf{Program} & \textbf{Version} & \textbf{Command} \\ \hline
cat  & 8.32 & cat pi.txt\\ \hline
grep & 3.7  & grep 1425 pi.txt\\ \hline
ls   & 8.32 & ls \\ \hline
nano & 6.2  & nano pi.txt\\ \hline
sed  & 4.8  & sed "s/1425/5241/g" pi.txt\\ \hline
wc   & 8.32 & wc pi.txt\\
\end{tabular}
\caption{The programs used to record allocation and free patterns from and the specific commands used to execute them.}
\label{table:pattern-programs}
\end{table}

Patterns have been recorded using the \texttt{LD\_PRELOAD} environment variable in Linux to hook into \texttt{malloc()} and \texttt{free()} and output the requests to a file, in the same order they were performed. The recorded pattern is then replayed on the different versions of the allocator in the same order they were recorded, essentially emulating the usage of the allocator in isolation.

\subsection{Measuring Fragmentation}

When reasoning about internal fragmentation in the different versions of the allocator, two things are of main concern: wasted space due to block header overhead and wasted space due to padding or alignment. Internal fragmentation will be gauged by numerically analyzing the worst-case scenario for all versions of the allocator. The analysis is suited toward ZGC by placing limitations on the allocators that align with small pages of ZGC. The heap size is set to 2MB, and the allowed allocation sizes are in the range [16B, 256KB]. To fairly compare the versions of the allocator, all allocations are aligned to 8 bytes, which is the same as pointer alignment on a 64-bit system.

Two worst-case scenarios are examined: (1) when maximum space is wasted due to both block headers and padding, and (2) when maximum space is wasted only due to block headers. For both cases, the heap will be filled with as many blocks as possible of the smallest possible allocation size. Keeping the allocation size range of ZGC small pages in mind, 17 bytes and 16 bytes will be allocated in the first and second cases respectively, since 17 bytes require maximum padding and 16 bytes require no padding.

Internal fragmentation is calculated in the following way, where the total allocation consists of block header, allocation, and padding. num\_blocks is rounded down to the nearest integer since a fraction of a block cannot be created.
\begin{align*}
    \text{waste} &= \text{block\_header} + \text{padding} \\\\
    \text{num\_blocks} &= \frac{2\text{MB}}{\text{block\_header + allocation + padding}} \\\\
    \text{internal\_fragmentation} &= \frac{\text{num\_blocks} \cdot \text{waste}}{2\text{MB}}
\end{align*}

The goal of this evaluation is to see how much memory could theoretically be wasted when using the different versions of the allocator. The final results will give us a range of worst-case memory wastage, which will vary depending on the amount of padding that is applied. In practice, the allocator will most likely never reach the calculated worst-case since all allocations will unlikely be of the same and lowest possible size. However, the results will provide an upper bound that can be used to reason about the memory efficiency of the allocators.

\subsection{Machine to Collect Data}

Performance benchmarks are run on the machine with the specifications shown in Table~\ref{table:machine}. Each version of the allocator is compiled using GCC 11.4.0 with the C++14 standard (\texttt{-std=c++14}) using optimization level two (\texttt{-O2}).

\begin{table}[H]
    \centering
\begin{tabular}{lp{11.3cm}}
    \textbf{Configuration} & \textbf{Machine} \\ \hline
CPU           & AMD Opteron 6274 @ 2.2 GHz with 8 cores (2 threads/core)\\ \hline
Memory        & 110GB                                                   \\ \hline
L1 Cache      & 512KB                                                   \\ \hline
L2 Cache      & 32MB                                                    \\ \hline
L3 Cache      & 24MB                                                    \\ \hline
System        & Ubuntu 22.04.4 LTS (Jammy Jellyfish)                    \\ \hline
Kernel        & Linux 5.15.0-101-generic
\end{tabular}
\caption{Machine used to collect data.}
\label{table:machine}
\end{table}
