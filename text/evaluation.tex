
When evaluating memory allocators, two primary metrics stand out: performance and memory usage, specifically fragmentation. Performance entails measuring the duration it takes to perform certain operations, while fragmentation assesses how efficiently the allocator utilizes the available memory.

\subsection{Evaluation Delimitations}

To reiterate, the allocator designed in this work will not be integrated into ZGC, as there is simply not enough time to do so in the context of this work. Integration into ZGC would provide a natural environment to test and evaluate the allocator in. Choosing not to do this impacts the way in which the allocators can be evaluated definitively.

The optimized version of the allocator is tailored toward ZGC to the extent that it limits the pattern of allocations and frees that can be used on it. This makes it hard to find overlapping areas where the different versions of the allocator can be fairly compared and to finding suitable patterns given the limits on allocation and heap size that the optimized version has. Part of what makes this hard is that even when applying the same pattern of allocations and frees, their respective heaps will be filled differently, and at different speeds. This is mainly due to the fact that the different versions have different sizes for the block header, making them use varying amounts of memory. For example, when the general version fills its heap, the optimized version may still have some portion of unused memory available. Additionally, the optimized version does not support immediate coalescing. This also affects the way that the heap is filled and makes it unclear when to perform explicit coalescing so that the same allocation requests can be fulfilled on all versions of the allocator.

Because of these difficulties, evaluation is limited to cases that can be fairly compared and reasoned about. This method is not exhaustive, which is often the case when evaluating allocators in general, but will provide a level on which to reason about the relative performance of the versions of the allocator.

\subsection{Allocator Configurations}

The three different versions of the TLSF allocator developed in this work that will be evaluated and compared in this section are: the reference TLSF implementation, the general version and the optimized version for ZGC. 

The general and optimized versions are described by their configuration variables from the base implementation, as shown in Table~\ref{table:configuration-variables}.

\begin{table}[H]
    \centering
    \begin{tabular}{lp{2cm}p{6.9cm}}
    \textbf{{Configuration Variable}} & \textbf{{General}} & \textbf{{Optimized}} \\ \hline
    First-Level Index         & 32       & 14     \\ \hline
    Second-Level Index (log2) & 5        & 2      \\ \hline
    Minimum Block Size        & 32       & 16     \\ \hline
    Use Second Levels         & True     & False  \\ \hline
    Use Deferred Coalescing   & False    & True   \\ \hline
    Block Header Length       & 32       & 0        
    \end{tabular}
    \caption{Configuration variables for the general and optimized versions of the allocator.}
    \label{table:configuration-variables}
\end{table}

\subsection{Measuring Performance}

In order to fairly compare the versions of the allocators when doing benchmarks that call \texttt{free()}, immediate coalescing will be disabled for the reference and general versions, by not attempting to implicitly coalesce blocks in a call to \texttt{free()}. This is because the optimized version does not support immediate coalescing and only implements explicit coalescing, which is intentionally slower due to the fact it should be used only as a last-resort. Disabling immediate coalescing is also reasonable from the perspective that it is likely not desirable as often in Z, making the test more adapted to the intended use-case of the optimized version.

Performance will be measured by looking at three different benchmarks: single allocation, single free and patterns that combine both allocation and free requests.

Three scenarios for single allocation are considered, all focusing on a fixed size of 64 bytes. Only allocating a single size comes from TLSF's constraint on the maximum number of instructions required for block allocation. Consequently, assessing multiple sizes becomes redundant as allocation performance primarily depends on the availability of suitable blocks within the free-lists. The first two cases that are considered are when there exists a block in the heap that perfectly align with the allocation size, and another where there only exists a block that is larger than the allocation size. The latter case requires, in addition to doing the same operations as in the first case, searching the bitmap for a larger block and splitting it. This case is also used as the worst case test by M. Masmano et al.~\cite{TLSF} for the evaluation of the original TLSF design. The third case will be performing the first case and also initializing the returned memory by filling it with zeros. This is to see how initializing the memory affects performance, as this is done after allocating memory in ZGC. Measuring these three cases will provide insight into both normal and worst-case allocation performance.

Measuring single frees is more straightforward to reason about than allocation, since immediate coalescing is disabled. Calling \texttt{free()} with coalescing disabled can only be performed in a single way, by inserting the free block into the appropriate free-list. The test that will be performed will allocate 64 bytes and then call free on the returned address immediately after. Time will be measured right before and after the call to \texttt{free()}.

In a more comprehensive performance test, a pattern of both allocation and free requests will be applied. Due to the limitations mentioned in the previous section, patterns that adhere to the requirements of the optimized version are used. Patterns will be recorded from the GNU utilities: \texttt{cat}, \texttt{grep}, \texttt{ls}, \texttt{nano}, \texttt{sed} and \texttt{wc}, which are then applied to the different versions of the allocator to compare performance. The reason this is done instead of just using the allocators in the programs is to highlight only the performance of allocating and freeing. Using the allocators in the programs would spend significantly more time doing program logic instead of using the allocator, making it more difficult to see the performance impact of changing allocator.

All benchmarks will be measured using wall-clock-time to see their execution time and repeated 100000 times to collect a mean result. Benchmarks are repeated to remove nay jitter and noise from the results so that stable results are reported.

\subsubsection{Programs to Record Patterns From}

Table~\ref{table:pattern-programs} show the specific commands and versions of the programs used to record patterns. All programs except \texttt{ls} have performed their respective actions on the same file called \texttt{pi.txt}, which contains the first 10000 decimals of pi, line-broken every 100:th decimal to create 100 lines of 100 decimals. The \texttt{ls} command has been run inside a directory containing only the file \texttt{pi.txt}. The \texttt{nano} command opens \texttt{pi.txt} and exits immediately.

\begin{table}[H]
\centering
\begin{tabular}{llp{10.4cm}}
\textbf{Program} & \textbf{Version} & \textbf{Command} \\ \hline
cat  & 8.32 & cat pi.txt\\ \hline
grep & 3.7  & grep 1425 pi.txt\\ \hline
ls   & 8.32 & ls \\ \hline
nano & 6.2  & nano pi.txt\\ \hline
sed  & 4.8  & sed "s/1425/5241/g" pi.txt\\ \hline
wc   & 8.32 & wc pi.txt\\
\end{tabular}
\caption{The programs used to record allocation and free patterns from and the specific commands used to execute them.}
\label{table:pattern-programs}
\end{table}

Patterns have been recorded using the \texttt{LD\_PRELOAD} environment variable in Linux to hook into \texttt{malloc()} and \texttt{free()} and output the requests to a file, in the same order they were performed. The recorded pattern is then replayed on the different versions of the allocator in the same order they were recorded, essentially emulating the usage of the allocator in isolation.

\subsection{Measuring Fragmentation}

When reasoning about internal fragmentation in the different versions of the allocator, two things are of main concerns: wasted space due to block header overhead and wasted space due to padding/alignment. Internal fragmentation will be gauged by numerically analyzing the worst-case for all versions of the allocator. The analysis is suited toward ZGC by placing limitations on the allocators that align with small pages of ZGC. The heap size is set to 2MB and allowed allocation sizes are in the range [16B, 256KB]. To fairly compare the versions of the allocator, all allocations are aligned to 8 bytes, which is the same as pointer alignment on a 64-bit system.

Two worst-cases are examined: (1) when maximum space is wasted due to both block header and padding, and (2) when maximum space is wasted only due to block header. For both cases, the heap will be filled with as many blocks as possible of the smallest possible allocation size. Keeping the allocation size range of ZGC small pages in mind, 17 bytes and 16 bytes will be allocated in the first and second case respectively, since 17 bytes requires maximum padding and 16 bytes require no padding.

Internal fragmentation is calculated in the following way, where the total allocation consists of block header, allocation and padding. num\_blocks is round down to the nearest integer since a fraction of a block cannot be created.
\begin{align*}
    \text{waste} &= \text{block\_header} + \text{padding} \\\\
    \text{num\_blocks} &= \frac{2\text{MB}}{\text{block\_header + allocation + padding}} \\\\
    \text{internal\_fragmentation} &= \frac{\text{num\_blocks} \cdot \text{waste}}{2\text{MB}}
\end{align*}

The goal of this evaluation is to see how much memory could theoretically be wasted when using the different versions of the allocator. The final results will give us a range of worst-case memory wastage, which will vary depending on the amount of padding that is applied. In practice, the allocator will most likely never reach the calculated worst-case since all allocations will unlikely be of the same and lowest possible size. However, the results will provide an upper-bound that can be used to reason about the memory efficiency of the allocators.

\subsection{Machine to Collect Data}

Performance benchmarks are run on the machine with the specifications shown in Table~\ref{table:machine}. Each version of the allocator is compiled using GCC 11.4.0 with the C++14 standard (\texttt{-std=c++14}) using optimization level two (\texttt{-O2}).

\begin{table}[H]
    \centering
\begin{tabular}{lp{11.3cm}}
    \textbf{Configuration} & \textbf{Machine} \\ \hline
CPU           & AMD Opteron 6274 @ 2.2 GHz with 8 cores (2 threads/core)\\ \hline
Memory        & 110GB                                                   \\ \hline
L1 Cache      & 512KB                                                   \\ \hline
L2 Cache      & 32MB                                                    \\ \hline
L3 Cache      & 24MB                                                    \\ \hline
System        & Ubuntu 22.04.4 LTS (Jammy Jellyfish)                    \\ \hline
Kernel        & Linux 5.15.0-101-generic
\end{tabular}
\caption{Machine used to collect data.}
\label{table:machine}
\end{table}
