
When evaluating memory allocators, two primary metrics stand out: performance and memory usage, specifically fragmentation. Performance entails measuring the duration it takes to perform certain operations, while fragmentation assesses how efficiently the allocator utilizes the available memory.

\subsection{Evaluation Delimitations}

To reiterate, we will not integrate the allocator into ZGC, as there is simply not enough time to do so in the context of this work. Integration into ZGC would provide a natural environment to test and evaluate the allocator in. Choosing not to do this makes it harder to devise ways in which is descriptive enough to give an indication of how the allocator would behave in that environment. 

The optimized version of the allocator is tailored toward ZGC to the extent that it limits greatly the kind of allocation and free pattern that can be used on it. This makes it hard to find overlapping areas where the different versions of the allocator can be fairly compared and to find allocation and free patterns given the limits on allocation and heap size that the optimized version has. Part of what makes this hard is that even when applying the same pattern of allocations and frees, their respective heaps would be filled differently, and at different speeds. This is mainly due to the fact that the different versions have different sizes for the block header, making them use varying amounts of memory. For example, when the general version fills its heap, the optimized version may still have some portion of unused memory available. Additionally, the optimized version does not support immediate coalescing. This affects the way that the heap is filled and makes it unclear when to perform explicit coalescing so that the same allocation requests can be fulfilled on all versions of the allocator.

Because of these difficulties, we have chosen to limit evaluation of the allocator to fundamental metrics that are clear to reason about. Specifically, we will focus on performance in terms of a single allocation request and memory efficiency, which will be assessed through an analysis of worst-case scenarios. While this approach allows us to reason about the behavior of the optimized allocator in independence, it may not fully capture its performance in a production environment using ZGC. However, it will provide insight into how the adaptations affect the performance and memory efficiency of the allocator, which addresses the third research question.

\subsection{Allocator Configurations}

The three different versions of the TLSF allocator developed in this work that will be evaluated and compared in this section are: the reference TLSF implementation, the general version and the optimized version for ZGC. 

The general and optimized versions are described by their configuration variables from the base implementation, as shown in Table~\ref{table:configuration-variables}.

\begin{table}[H]
\centering
\begin{tabular}{lllll}
\hline
Configuration Variable  & General  & \multicolumn{3}{l}{Optimized} \\ \hline
First-Level Index       & 32       & \multicolumn{3}{l}{14}        \\
Second-Level Index      & 5        & \multicolumn{3}{l}{2}         \\
Minimum Block Size      & 32       & \multicolumn{3}{l}{16 }       \\
Use Second Levels       & True     & \multicolumn{3}{l}{False}     \\
Use Deferred Coalescing & False    & \multicolumn{3}{l}{True}      \\
Block Header Length     & 32       & \multicolumn{3}{l}{0}        
\end{tabular}
\caption{Configuration variables for the general and optimized versions of the allocator.}
\label{table:configuration-variables}
\end{table}

\subsection{Measuring Performance}

Since the design of TLSF is such that it sets an upper bound on the number of instructions required to allocate memory, it is not necessary to measure allocation of multiple different sizes. Instead, we will only measure allocation of a single size, 64 bytes. 

Three cases will be measured, of which the first two are: one where there exists a block in the heap that perfectly align with the allocation size, and another where there only exists a block that is larger than the allocation size. The latter case requires, in addition to doing the same operations as in the first case, searching the bitmap for a larger block and splitting it. This case is also used as the worst case test by M. Masmano et al.~\cite{TLSF} for the evaluation of the original TLSF design. The third case will be performing the first case and also initializing the returned memory to 0. This is to see how initializing the memory affects performance, as this is done after allocating memory in ZGC. Measuring these three cases will provide insight into both normal and worst-case allocation performance.

To measure performance we will look at the time it takes to perform the two cases for all three versions of the allocator. The measurements will tell us how the adaptations that have been made to the optimized version affect its performance when doing its most fundamental operation. To improve the reliability of the results, measurements will be collected by running the tests 100000 times and taking the mean value. Time is measured using the POSIX function \texttt{clock\_gettime()} with the clock set to \texttt{CLOCK\_MONOTONIC\_RAW}. Measurements are made right before and after calling \texttt{malloc()} on the allocator and the difference between the two is reported.

\subsection{Measuring Fragmentation}

When reasoning about internal fragmentation in the different versions of the allocator, we are concerned about two things: wasted space due to block header overhead and wasted space due to padding/alignment. To gauge internal fragmentation without having to rely on a pattern of allocations and free requests, we will numerically analyze the worst-case of fragmentation for all versions of the allocator. To make the analysis suited toward ZGC, we place limitations on the allocators that align with small pages of ZGC. The heap size is set to 2MB and allowed allocation sizes are in the range [16B, 256KB]. Additionally, even though one might use different alignment for the different allocators, to fairly compare them we will align allocations to 8 bytes on all allocators, since we are running on a 64-bit system.

We will examine two worst-cases: (1) when maximum space is wasted due to both block header and padding, and (2) when maximum space is wasted only due to block header. For both of these cases, the smallest possible size will be allocated to fill the heap with as many blocks as possible. Keeping the smallest allocation size of ZGC small pages in mind, 17 bytes and 16 bytes will be allocated in the first and second case respectively, since 17 bytes requires maximum padding and 16 bytes require no padding.

Internal fragmentation is calculated in the following way, where the total allocation consists of block header, allocation and padding. num\_blocks is round down to the nearest integer since a fraction of a block cannot be created.

\begin{align}
    \text{waste} &= \text{block\_header} + \text{padding} \\
    \text{num\_blocks} &= \frac{2\text{MB}}{\text{block\_header + allocation + padding}} \\
    \text{internal\_fragmentation} &= \frac{\text{num\_blocks} \cdot \text{waste}}{2\text{MB}}
\end{align}

From looking at the sizes of the block headers, it is straightforward to conclude which allocator uses less memory overall since smaller header would mean less memory used overall when allocating the same size. However, the goal of this evaluation is to see how much memory could theoretically be wasted when using different versions of the allocator, which also includes padding. The final results will give us a range of worst-case memory wastage, which will vary depending on the amount of padding that is applied. In practice, the allocator will most likely never reach the calculated worst-case since all allocations will unlikely be of the same size. However, the results will provide an upper-bound that can be used to reason about the effectiveness of the allocator.

\subsection{Machine to Collect Data}

Performance benchmarks have been run on two machines. The specifications for these machines are shown in Table~\ref{table:machines}. Each version of the allocator is compiled using GCC 11.4.0 with the C++14 (\texttt{-std=c++14}) standard using optimization level two (\texttt{-O2}).

\begin{table}[H]
\begin{tabular}{cp{5.54cm}p{5.54cm}}
Configuration & Machine A                                                & Machine B                                              \\ \hline
CPU           & AMD Opteron 6274 @ 2.2 GHz with 8 cores (2 threads/core) & Intel i7-1185G7 @ 3.0 GHz with 4 cores (2threads/core) \\ \hline
Memory        & 110GB                                                    & 16GB                                                   \\ \hline
L1 Cache      & 512KB (L1d), 1MB (L1i)                                   & 192KB (L1d), 128 KB (L1i)                              \\ \hline
L2 Cache      & 32MB                                                     & 5MB                                                    \\ \hline
L3 Cache      & 24MB                                                     & 12MB                                                   \\ \hline
System        & \multicolumn{2}{c}{Ubuntu 22.04.4 LTS (Jammy Jellyfish)}                                                          \\ \hline
Kernel        & Linux 5.15.0-101-generic                                 & Linux 6.5.0-26-generic                                
\end{tabular}
\caption{Machines used to collect data.}
\label{table:machines}
\end{table}

