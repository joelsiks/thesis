
% Link results to research questions. Explain what the experiments tell you about your research questions. If any of the experiments “failed” or did not behave as ex- pected, try to reason about potential explanations and propose additional experiments that could be performed to lead the investigation further.

% Limitations and future work. Describe the limitations of your work, i.e., under what assumptions do your conclusions hold? What potentially relevant aspects were outside the scope of your study? Possibly, suggest avenues for future work building upon your study.

Exhaustive and comprehensive benchmarking of allocators is not feasible, and the performance results should not be interpreted as definitive. The performance benchmarks and results do not necessarily indicate how Java-programs will perform when using the allocator in ZGC. Applying patterns instead of using the allocators directly inside programs is also not optimal as it does not show how the allocators behave in practice. For example, without program logic mixed in between allocations and frees, the cache-locality is not fully representative, which might impact performance and thus the reliability of the results. With these considerations in mind, the benchmarks do however compare the allocators on a level which is fairly defined, allowing us to reason about their relative performance. 

From the results we can conclude that for single allocations, the optimized version is comparable in performance to the reference version, but is about 25\% slower than the reference version for single frees. When applying patterns from a selection of real-world programs, the optimized version is about 12\% slower on average. 

For programs with fewer total operations, the optimized version is observed to be slower than for programs with more total operations, even though the programs with more operations perform more frees, which should, considering the performance of single frees, be slower overall. One reason for this might be cache-performance and memory re-use playing a larger role in programs that do more operations than fewer. Taking into account that the results of the benchmarks are limited, a hypothesis that can be made is that performing more total operations over time makes the difference in performance between the reference and optimized versions less noticeable; this requires further examination, but might be of interest when considering using an allocator in ZGC, where it could be desirable to use the allocator in scenarios where many operations are done.

The largest adaptation of the allocator is the concept of the 0-byte header. The 0-byte header stores no information inside allocated blocks, but uses the first 16 bytes of a free block to store metadata, and thus requires the minimum allocation size to be 16, which aligns well with the same limit that ZGC has. In addition to using less memory, the adaptation allows allocated memory to be packed more closely, making more memory fit inside the same cache-line, increasing cache-locality, and likely performance as a result. This is a major benefit that is likely to yield better performance, and is similarly defined to the Lilliput project~\cite{lilliput} in the OpenJDK, that aims to reduce the size of the Java object header to reduce memory footprint. Lilliput and its implications are further discussed and reasoned about in Section~\ref{sec:future-work:lilliput}, as future work.

\newpage

Analyzing the worst-case scenario of internal fragmentation, of the optimized version, we demonstrate that the only cause of internal fragmentation is padding. Since the optimized version is able to completely remove the block header for allocated blocks, there is practically no memory overhead for allocated blocks apart from padding. In terms of internal fragmentation, we conclude that there is no difference between the optimized version and bump-pointer allocation, which also applies padding to meet alignment requirements.

The idea behind the name of the TLSF allocator is now more obscure since the two-level bitmaps are now flattened to a single bitmap, able to fit in a 64-bit word due to the limited allocation size range of ZGC's small pages. The main benefit of using bitmaps is still present, namely being able to efficiently look up free-lists containing blocks using fast bit instructions. However, limiting the allocation size range greatly reduces the granularity of size ranges of the free-lists. This is likely not a problem since the highest granularity is found for the lowest size ranges, where most allocations occur in Java programs, but should be taken into consideration when using the allocator in practice. Another benefit of flattening the bitmaps, apart from performance and memory efficiency, is that the new bitmap can be atomically operated on, which is beneficial for concurrency.

% Maybe discuss that concurrency would be possible to implement without any of the adaptations, but is made significantly easier with the adaptations that have been done. Making the free-lists lock-free would be hard when keeping track of all informtaion present in the reference design.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
