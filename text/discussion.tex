
The most significant adaptation of the allocator is the concept of the 0-byte header. The 0-byte header stores no information inside allocated blocks but uses the first 16 bytes of a free block to store metadata and thus requires the minimum allocation size to be 16, which aligns well with the same limit that ZGC has. In addition to using less memory, the adaptation allows allocated memory to be packed more closely, making more memory fit inside the same cache line, increasing cache locality, and likely performance as a result. This benefit is similarly defined to the ones listed for the Lilliput project~\cite{lilliput} in the OpenJDK, which aims to reduce the size of the Java object header to reduce memory footprint. Lilliput and its implications are further discussed and reasoned about in Section~\ref{sec:future-work:lilliput}, as future work.

Exhaustive and comprehensive benchmarking of allocators is not feasible, and the performance results should not be interpreted as definitive. The performance benchmarks and results do not necessarily indicate how Java programs will perform when using the allocator in ZGC. Applying patterns instead of using the allocators directly inside programs is also not optimal, as it does not show how the allocators behave in practice. For example, without program logic mixed in between allocations and frees, the cache locality is not fully representative, which might impact performance and thus the reliability of the results. With these considerations in mind, the benchmarks do, however, compare the allocators on a level that is fairly defined, allowing us to reason about their relative performance. 

From the results, it can be concluded that for single allocations, the optimized version is comparable in performance to the reference version but is about 25\% slower than the reference version for single frees. When applying patterns from a selection of real-world programs, the optimized version is about 12\% slower on average. It is hard to draw precise conclusions about the results of applying patterns from real-world programs. 

A hypothesis was that for programs with more total operations, the optimized version would perform better than for programs with fewer operations because the optimized version has better cache locality. This turned out not to be the case, as there is practically no difference between \texttt{grep} and \texttt{nano}, which have 395 and 8750 operations, respectively. The impact of the improved cache locality was harder to measure than anticipated. The exact impact the cache locality has on performance will need to be further examined to fully understand its potential effect.

Analysis of the worst-case scenario of internal fragmentation in the optimized version demonstrates that the only cause of internal fragmentation is padding. Since the optimized version is able to completely remove the block header for allocated blocks, there is practically no memory overhead for allocated blocks apart from padding. In terms of internal fragmentation, it can be concluded that there is no difference between the optimized version and bump-pointer allocation, which also applies padding to meet alignment requirements.

The concept behind the name TLSF has become somewhat ambiguous following the transition from two-level bitmaps to a single bitmap that fits within a 64-bit word, made possible from the limited allocation size range of ZGC's small pages. The main advantage of using bitmaps remains, namely the ability to efficiently look up free-lists containing blocks using fast bit instructions. However, limiting the allocation size range significantly reduces the granularity of the free-list size ranges. This reduction in granularity is unlikely to pose a problem, as the highest granularity is found in the smallest size ranges where most allocations occur in Java programs. Nonetheless, this should be considered when using the allocator in practice. Importantly, an additional benefit of the new bitmap design, apart from performance and memory efficiency, is that it can be atomically operated on, which is advantageous for concurrency.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
