In this section we describe adaptations of the reference implementation of the TLSF allocator to make it more suited toward being used in the context of a garbage collector, specifically ZGC. The implementations of the adaptations proposed here, and their impact, are explained in Section~\ref{sec:adaptations-impl}. For each adaptation in this section, we will also go over why they are reasonable to do.

\subsection{Architectural Considerations}
\label{sec:adaptations:architectural-considerations}

ZGC is solely implemented for 64-bit architecture and does not support 32-bit~\cite{zgc_deep_dive}. Hence, in our effort to adapt the allocator for ZGC, it is reasonable for it to also be limited to the same scope. The authors of TLSF have designed their allocator primarily for 32-bit systems due to it being targeted toward real-time embedded systems, which usually operate on 32-bit architecture. However, with its intended target in mind, the design principles and concepts of TLSF are not inherently tied to any specific architecture. Converting TLSF from 32-bit to 64-bit mainly requires aligning memory to a word size of 8 bytes instead of 4, which does add a slightly larger memory overhead if allocations are not using the extra memory.

As explained in Section~\ref{sec:tlsf}, the two least significant bits within the block header are reserved for metadata. However, now that we are aligning addresses to 8 bytes instead of 4 bytes, we get an extra bit that can be used to store metadata in. We will discuss a possible use of this extra bit in Section~\ref{sec:future-work:lilliput}.

\subsection{General and Optimized Versions}

% TODO: Ta upp att det är mycket relevant att hålla antalet rader kod minimalt eftersom OpneJDK redan är mycket omfattande och det är vettigt att hålla underhållnadskostnader nere.

When further adapting the allocator we will consider the use cases of either using it as a normal allocator in cases where a traditional malloc/free combination is used, or as a way to allocate objects on pages in ZGC. A way to realize this is by making the allocator configurable, similarly to what E. Berger et al.~\cite{configurable_allocator} have done, utilizing C++ templates and inheritance. Having a configurable allocator is not only desirable from a maintenance perspective, but it also allows adaptation for changing environment and requirements. Additionally, it becomes easier to compare different versions of the allocator by changing the configuration, streamlining the process of measuring the efficacy of any potential improvements.

Moving on, we will refer to the use-case of using the allocator as a general allocator as the general version, and the adapted, or optimized, version for ZGC as the optimized version. The general version will aim to be as similar to the reference implementation as possible.

\subsection{Reduced Allocation Size Range}
\label{sec:adaptations:reduced_allocation_range}
%We note that the allowed sizes in the medium range is a factor of 16KB larger than the small range. This allows us to limit the allocator to the size range of small page, with an additional multiplication factor of 1 for small pages and 16KB for medium pages.

In ZGC, small pages limits the user to allocate in a specific size range, namely [16B, 256KB], as mentioned in Section~\ref{sec:zpage}. To our advantage, we can use this to store metadata about the allocator in a more efficient way. Specifically, we are able to limit the number of free-lists that are needed and in turn the number of bits needed in the bitmaps.

We need 14 first-levels to be able to index every power of two inside the small page range, with a lower-bound of $2^4 =$ 16B and an upper-bound of $2^{17} =$ 128KB. It is desirable to store all bitmap information in a single 64-bit word for performance reasons, both in terms of cache efficiency and usage of efficient bit instructions on lookup. If we want to stay inside the 64-bit limit, we must choose the number of second-levels accordingly. For efficiency reasons again, the number of second levels should be a power of two~\cite{TLSF} so that bit-shift instructions can be used. The only value this leaves us is 4, which results in $14 * 4 =$ 56-bits for storing all necessary metadata.

Since a page is 2MB large, the initial block will be of that size as well, which is significantly larger than the maximum allocation size of 256KB. There are two ways to solve this: either break the initial block down into smaller blocks, or allow storing blocks larger than the maximum allocation size. For simplicity's sake, we will add another free-list that stores blocks larger than the maximum allocation size, called a ``large-list'' at the 57th-bit. This is not really a problem as the same methods for finding blocks in the bitmap can be used.

To summarize, we now only need 57-bits for storing all information necessary for all free-lists, which fits inside a word of 64-bits. Having a single word allows us to find free-lists that contain blocks faster, using a more simplified indexing process. Additionally, when considering concurrency later on, we can use atomic operations when performing updates on the bitmap. A potential drawback of reducing the number of second-levels down to only 4 is that it could have a negative impact on fragmentation.

% Benefits: Reduced memory overhead, cache efficiency, Simplified indexing (and Atomic operations??)
% Drawbacks: Reduce number of second-level partitions to 4, instead of more, which could have an impact on internal fragmentation.

\subsection{Transitioning Between Different Allocation Strategies}

Completely phasing out the utilization of bump-pointer allocation may not be optimal, especially when there is no constant requirement to allocate solely within the ``holes'' of a page, as bump-pointer allocation is very fast. Instead, users could employ bump-pointer allocation up to a certain point, at which it becomes advantageous to transition to a more sophisticated allocator for non-bump-pointer allocation.

Most allocators start with an unused chunk of memory, allowing them to track and keep an up-to-date record of what the underlying memory contains. However, in the case where transitioning from bump-pointer to using an allocator, the underlying memory have contents that is not represented in the allocator. To solve this, we need a way to update the allocator's internal representation to align with the contents of the memory. In ZGC, the latest live analysis of a page contains an accurate representation of what data is alive in the page's underlying memory. This information can therefore be used to update the allocator's internal representation after a transition to using an allocator.

The construction of the allocator's representation involves a two-step process that extends the optimized allocator's API. Initially, the representation must be cleared so that any previous data is removed. When clearing the allocator, a block is allocated to cover the entirety of the underlying memory. This allows the user to invoke a function to free blocks within specified ranges, allowing to selectively ``carve'' segments of free memory from the initially allocated block.

When freeing a range inside the allocator, a block that starts at the given address and with a given size is simply inserted as a free block into the corresponding free-list in the allocator. The method of doing it this way places all responsibility on the calling user to make sure that the blocks are in fact free and can be re-used when new allocations are made.

\subsection{Deferred Coalescing of Blocks}

In the process of allocating and freeing blocks within an allocator, the general preference is to always have as large blocks as possible available to fulfill larger requests. However, in scenarios where numerous small allocations are frequently made and free'd, the emphasis on coalescing blocks to accommodate larger requests in the future may not be worthwhile. Instead, coalescing of blocks will be deferred until a later point in time or none at all.

The idea behind deferred coalescing is that when the user calls \texttt{free()}, the block being freed is not implicitly attempted to be coalesced with its adjacent physical neighbors. Instead, the allocator's API is extended to include an explicit coalesce operation. This operation scans through all blocks and coalesces as many as possible. Unlike immediate coalescing, a deferred approach postpones the process until a later point when a larger block is required.

The explicit coalesce operation conducts a pass over all blocks, requiring only knowledge of the size of the current block to identify the location of the next block. This eliminates the need to store a pointer to the physical neighbor right before the current block, which is only used when coalescing in a \texttt{free()} call. The algorithm describing how the pass is done is shown in Algorithm~\ref{algorithm:coalesce_blocks}.

\begin{algorithm}[H]
current = first\_physical\_block\\
\While{current != nullptr} {
next = get\_next\_block(current)\;
\uIf{next != nullptr \textbf{and} current->is\_free() \textbf{and} next->is\_free()} {
    current = coalesce\_neighbors(current, next)\;
    insert\_block(current)\;
}
\Else {
    current = next
}
}
\label{algorithm:coalesce_blocks}
\caption{Algorithm for explicitly coalescing all possible free blocks in the allocator. Note that coalesce\_neighbors() removes both blocks from the free-list before the newly coalesced block is inserted.}
\end{algorithm}

\subsection{Block Header Adjustments}
\label{sec:adaptations:block-header-adjustments}

R. Jones et al.~\cite[Page 103]{gchandbook} discuss that in the context of using allocators in garbage collectors, it is a reasonable approach to remove certain parts of the so-called boundary tag, or block header for TLSF. This is because we know the precise context the allocator will be used in, as opposed to a general-purpose allocator, which allows us to omit perhaps redundant fields.

The goal of adjusting the header is to reduce the constant block header overhead required when allocating blocks. The reduction is applied to headers for all allocations, but is especially noteworthy for smaller blocks, where the header makes up a larger percent of the total used memory. This aligns well with the fact that most allocations in common Java programs are small, making it more significant.

From the list of adaptations discussed so far, we can observe that storing a pointer to the previous physical block is less relevant if the emphasis is shifted away from freeing, and in turn, coalescing blocks. Following this, the previous physical pointer can be removed from the block header in the optimized version to reduce the header overhead. Additionally, with respect to the reduced allocation size range discussed in Section~\ref{sec:adaptations:reduced_allocation_range}, we can further reduce the footprint of the block header by converting the next and prev pointers to offsets instead. This would convert 64-bit pointers to 32-bit offsets, narrowing down the addressable space to 4GB, which is more than enough to offset into ZGC's 2MB pages.

Furthermore, storing the size of allocated blocks is redundant if it is also stored somewhere else, namely in the garbage collector itself, which ZGC does. This allows us to remove the size field completely for allocated blocks and only store it for free blocks. This change will require the user to provide the block size upon calling \texttt{free()} so that the block can be inserted into the appropriate free-list.

\subsection{Concurrency}

Considering that ZGC is a concurrent garbage collector, it is reasonable for the allocator to also support concurrency. There are several potential use-cases within ZGC that could benefit from a concurrent allocator, such as thread-local garbage collection and reference-counting in the old generation. However, at this stage, the allocator will not be adapted to any specific use-case, apart from the general adaptation of it being concurrent. By incorporating concurrency into the allocator's design alongside other adaptations, it becomes better equipped to remain relevant for evolving use-cases beyond the scope of this thesis.

Concurrency will be implemented in the allocator so that allocations and free's can be done in a thread-safe manner. Previous adaptations, such as limiting the allocation size ranges, smaller bitmaps and block header adjustments, significantly facilitates the implementation of concurrency in the allocator. As will be discussed further in Section~\ref{sec:adaptations_impl:concurrency}, concurrency will be supported in a lock-free manner. This approach requires addressing challanges such as the ABA problem, which will be considered fully in Section~\ref{sec:adaptations_impl:aba_problem}.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
