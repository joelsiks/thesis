In this section we describe adaptations of the reference implementation of the TLSF allocator to make it more suited toward being used in the context of a garbage collector, specifically ZGC. The implementations of the adaptations described here and their impact are explained and discussed in Section~\ref{sec:adaptations-impl}.

\subsection{Architectural Considerations}
\label{sec:adaptations:architectural-considerations}

ZGC is solely implemented for 64-bit architecture and does not support 32-bit~\cite{zgc_deep_dive}. Hence, in our effort to adapt the allocator for ZGC, it is reasonable for it to also be limited to the same scope. The authors of TLSF have designed their allocator primarily for 32-bit systems due to it being targeted toward real-time embedded systems, which usually operate on 32-bit architecture. However, with its intended target in mind, the design principles and concepts of TLSF are not inherently tied to any specific architecture. The main change needed to convert the TLSF design from 32-bit to 64-bit is aligning memory to word size of 8 bytes instead of 4, which does add a slightly larger memory overhead if allocations are not using the extra memory.

As explained in Section~\ref{sec:tlsf}, the two least significant bits within the block header are reserved for metadata. However, now that we are aligning addresses to 8 bytes instead of 4 bytes, we get an extra bit that can be used to store metadata in. We will discuss a possible use of this extra bit in Section~\ref{sec:future-work:lilliput}.

\subsection{General and Optimized Versions}

When further adapting the allocator we will consider the use cases of either using it as a normal allocator in cases where a traditional malloc/free combination is used, or as a way to allocate objects on pages in ZGC. To minimize the codebase, which is desirable from a maintenance perspective, the allocator will be adapted in a way which allows it to be configured. A major benefit of doing this is that different configurations can easily be compared against each other, streamlining the process of measuring efficacy of any adaptations that are made.

Worth noting however, is that in the process of redesigning the allocator in a configurable manner, some changes that deviates from the reference implementation will have to be made. Such trade-offs, which will be discussed in more detail later, could be reasonable when extending the interface for supporting multiple configurations, or versions, of the allocator.

\subsection{Reduced Allocation Size Range}
\label{sec:adaptations:reduced_allocation_range}

In ZGC, small and medium pages only allow the user to allocate in certain size ranges. To our advantage, we can use this to store metadata about the allocator in a more efficient way. Small pages allow sizes in the range [16B, 256KB] and medium pages (256KB, 4MB], as mentioned earlier in Section~\ref{sec:zpage}. We note that the allowed sizes in the medium range is a factor of 16KB larger than the small range. This allows us to limit the allocator to the size range of small page, with an additional multiplication factor of 1 for small pages and 16KB for medium pages.

With the limited allocation size range for small pages in mind, we are able to limit the number of free-lists we need and in turn the bits used in the bitmaps. We need 14 first-levels to be able to index every power of two inside the small page range, with a lower-bound of $2^4 =$ 16B and an upper-bound of $2^{17} =$ 128KB. It is desirable to store all bitmap information in a single 64-bit word for performance reasons, both in terms of cache efficiency and usage of efficient bit instructions on lookup. If we want to stay inside the 64-bit limit, we must choose the number of second-levels accordingly. For efficiency reasons again, the number of second levels should be a power of two~\cite{TLSF} so that bit-shift instructions can be used. The only value this leaves us is 4, which results in $14 * 4 =$ 56 bits for storing all metadata.

Since a page is initially 2MB large, the initial block will be significantly larger than the maximum allocation size of 256KB. This means we either need to split it up into multiple blocks of smaller sizes or store it in a different free-list. To solve this we will add a last free-list that is called the "large-list", represented by the 57th bit. The large-list will store blocks that are above the largest index to support storing blocks that are initially very large.

% TODO: Cite TLSF paper.
% Benefits: Reduced memory overhead, cache efficiency, Simplified indexing (and Atomic operations??)
% Drawbacks: Reduce number of second-level partitions to 4, instead of more, which could have an impact on internal fragmentation.

\subsection{Transitioning Between Different Allocation Strategies}

Completely phasing out the utilization of bump-pointer allocation may not be optimal, especially when there is no constant requirement to allocate solely within the ``holes'' of a page. Instead, users could employ bump-pointer allocation up to a certain point, at which it becomes advantageous to transition to a more sophisticated allocator for non-bump-pointer allocation.

Most allocators start with an unused chunk of memory, allowing them to track and keep an up-to-date record of what the underlying memory contains. However, in the case where transitioning from bump-pointer to using an allocator, the underlying memory have contents that is not represented in the allocator. To solve this, we need a way to update the allocator's internal representation to align with the contents of the memory. In ZGC, the latest live analysis of a page contains an accurate representation of what data is alive in the page's underlying memory. This information can therefore be used to update the allocator's internal representation after a transition to using an allocator.

The construction of the allocator's representation involves a two-step process that extends the optimized allocator's API. Initially, the representation must be cleared so that any previous data is removed. When clearing the allocator, a block is allocated to cover the entirety of the underlying memory. This allows the user to invoke a function to free blocks within specified ranges, allowing to selectively ``carve'' segments free memory from the initially allocated block.

When freeing a range inside the allocator, a block that starts at the given address and with a given size is simply inserted as a free block into the corresponding free-list in the allocator. The method of doing it this way places all responsibility on the calling user to make sure that the blocks are in fact free and can be re-used when new allocations are made.

\subsection{Deferred Coalescing of Blocks}

In the process of allocating and freeing blocks within an allocator, the general preference is to always have as large blocks as possible available to fulfill larger requests. However, in scenarios where numerous small allocations are frequently made and free'd, the emphasis on coalescing blocks to accommodate larger requests in the future may not be worthwhile. Instead, coalescing of blocks will be deferred until a later point in time or none at all.

The idea behind deferred coalescing is that when the user calls free(), the block being freed is not implicitly attempted to be coalesced with its adjacent physical neighbors. Instead, the allocator's API is extended to include an explicit coalesce operation. This operation scans through all blocks and coalesces as many as possible. Unlike immediate coalescing, this deferred approach postpones the process until a later point when a larger block is required.

The explicit coalesce operation conducts a pass over all blocks, requiring only knowledge of the size of the current block to identify the location of the next block. This eliminates the need to store a pointer to the physical neighbor right before the current block, which is only used when coalescing in a free() call. The algorithm describing how the pass is done is shown in Algorithm~\ref{algorithm:coalesce_blocks}.

\begin{algorithm}[H]
current = first\_physical\_block\\
\While{current != nullptr} {
next = get\_next\_block(current)\;
\uIf{next != nullptr \textbf{and} current->is\_free() \textbf{and} next->is\_free()} {
    current = coalesce\_neighbors(current, next)\;
    insert\_block(current)\;
}
\Else {
    current = next
}
}
\label{algorithm:coalesce_blocks}
\caption{Algorithm for explicitly coalescing all possible free blocks in the allocator. Note that coalesce\_neighbors() removes both blocks from the free-list before the newly coalesced block is inserted.}
\end{algorithm}


\subsubsection{Block Header Adjustments}

R. Jones et al.~\cite[Page 103]{gchandbook} discuss that in the context of using allocators in garbage collectors, it is a reasonable approach to remove certain parts of the so-called boundary tag, or block header for TLSF. This is because we know the precise context the allocator will be used in, as opposed to a general-purpose version of the allocator designed for many use-cases.

From the list of adaptations discussed so far, we can observe that storing a pointer to the previous physical block is less relevant if the emphasis is shifted away from freeing, and in turn, coalescing blocks. Following this, the previous physical pointer can be removed from the block header in the optimized version to reduce the header overhead. Additionally, with respect to the reduced allocation size range discussed in Section~\ref{sec:adaptations:reduced_allocation_range}, we can further reduce the footprint of the block header by converting the next and prev pointers to offsets instead. This is reasonable since 

From the list of adaptations discussed so far, we can observe that storing a pointer to the previous physical block is no longer necessary in the optimized version. This because the previous physical pointer is only used when calling free and coalescing blocks with their physical neighbors. Both of these use-cases will be less relevant in the optimized version and thus allows us to slim the header by removing the previous physical block pointer.

The goal of changing the header is to reduce the constant block header overhead required when allocating blocks. This is especially important when most allocations are small, where the block overhead is most significant. With the new design for the block header, the constant block header overhead for the optimized version is reduced to only 8 bytes for storing the size of the block. However, reducing the overhead for optimized headers has required us to instead increase the overhead for the general version.


We would also want to reduce the overhead for storing the next and prev pointers to be offsets instead, which

\subsection{Concurrency}

% Use cases. List them and what we need to be able to solve.
% Thread-Local GC?

% TODO: Disadventageous for small allocations, will have to be measured in practice.
% Block sizes can be stored in much less than 64 bits, but due to alignment etc it is reasonable to use a 64-bit value to store the size anyways.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
